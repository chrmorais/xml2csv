<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>NRI: Large-Scale Collaborative Semantic Mapping using 3D Structure from Motion</AwardTitle>
    <AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2017</AwardExpirationDate>
    <AwardAmount>391990</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Directorate for Computer &amp; Information Science &amp; Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Jie Yang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>The project develops techniques to advance the state of the art in tackling the challenges associated with creating such representations using robots, namely issues related to the scalability and semantic interpretability of such maps. The research activities include advancement of knowledge in multiple fields, such as computer vision, structure from motion, robotics, and semantic mapping. The results have the potential for many societal applications including city planning, asset management, creation of historical records, and support for autonomous driving. The demonstration of the developed theoretical techniques for real-time interaction between humans and robots facilitated by a semantic map enables even greater societal benefit, for example for emergency management, crime prevention, and traffic management. Direct educational impact is anticipated for graduate students and the results are disseminated through both publications and software, allowing the community to leverage the results.&lt;br/&gt;&lt;br/&gt;This research program advances real-time large-scale distributed semantic mapping of outdoor environments. Specifically, the research team is enabling real-time large-scale semantic mapping by using unsupervised object discovery, obviating the need for large sets of annotated videos for each object category which becomes prohibitive when dealing with hundreds of object categories. The research team frames this process within the structure from motion optimization framework, thereby leveraging geometric and multi-view constraints and features to increase reliability of object track association as well as category clustering. In addition to address scalability, the project develops a distributed, multi-robot system, allowing large teams of air and ground vehicles to cooperatively build a map of large geographic areas in reasonable time frames. Furthermore, the project develops techniques to make the maps more semantically-meaningful and hence interpretable by humans. To accomplish this objective, the research team uses automatic techniques to attach semantic labels to objects discovered in an unsupervised manner. Moreover, humans can interact with the system at multiple levels. Human users can refine both the object categories and semantic labels to increase their accuracy, as well as designate dynamic targets of interest and task robots to track them.</AbstractNarration>
    <MinAmdLetterDate>08/22/2014</MinAmdLetterDate>
    <MaxAmdLetterDate>09/12/2014</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1426998</AwardID>
    <Investigator>
      <FirstName>Frank</FirstName>
      <LastName>Dellaert</LastName>
      <EmailAddress>dellaert@cc.gatech.edu</EmailAddress>
      <StartDate>08/22/2014</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Zsolt</FirstName>
      <LastName>Kira</LastName>
      <EmailAddress>zkira@gatech.edu</EmailAddress>
      <StartDate>08/22/2014</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Georgia Tech Applied Research Corporation</Name>
      <CityName>Atlanta</CityName>
      <ZipCode>303320420</ZipCode>
      <PhoneNumber>4048944819</PhoneNumber>
      <StreetAddress>Office of Sponsored Programs</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Georgia</StateName>
      <StateCode>GA</StateCode>
    </Institution>
  </Award>
</rootTag>
