<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Adjusting for Unit Nonresponse That May Not be Missing at Random</AwardTitle>
    <AwardEffectiveDate>10/01/2014</AwardEffectiveDate>
    <AwardExpirationDate>09/30/2015</AwardExpirationDate>
    <AwardAmount>145000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>04050000</Code>
      <Directorate>
        <LongName>Directorate for Social, Behavioral &amp; Economic Sciences</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Social and Economic Sciences</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Cheryl L. Eavey</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This research project will further understanding of a statistical technique for measuring and reducing the potential for biases from non-response in sample surveys. Sample surveys are a principal tool for providing accurate information crucial for good economic and social decision making. Nonresponse in sample surveys conducted both privately and by government agencies is increasing. With that increase, the potential for serious biases in estimates derived from surveys and used in critical decision making grows. This research will address that problem, particularly in cases where non-response may be a function of variables having missing values. Extensions of this research will have broad application to multi-phase surveys, non-probability surveys, and other statistical applications plagued by potential selection bias whether due to nonresponse, coverage errors, or both. The project will develop powerful, publically available tools for implementing this approach.&lt;br/&gt;&lt;br/&gt;Calibration weighting can be used to remove potential selection biases due to unit non-response or coverage errors. This research project will demonstrate the advantages in terms of reductions in non-response bias and increases in accuracy of having more calibration than model variables when non-respondents are determined not to be missing at random. In so doing, it will introduce a better method of calibration weighting in this context than currently exists in the literature. The research also will investigate new tests for determining whether a set of calibration variables can by itself serve as the model variables or whether a survey variable truly needs to be added to the response model to avoid selection bias. The project is supported by the Methodology, Measurement, and Statistics Program and a consortium of federal statistical agencies as part of a joint activity to support research on survey and statistical methodology.</AbstractNarration>
    <MinAmdLetterDate>08/25/2014</MinAmdLetterDate>
    <MaxAmdLetterDate>08/25/2014</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1424492</AwardID>
    <Investigator>
      <FirstName>Phillip</FirstName>
      <LastName>Kott</LastName>
      <EmailAddress>pkott@rti.org</EmailAddress>
      <StartDate>08/25/2014</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Research Triangle Institute</Name>
      <CityName>Research Triangle Park</CityName>
      <ZipCode>277092194</ZipCode>
      <PhoneNumber>9195416000</PhoneNumber>
      <StreetAddress>3040 Cornwallis Road</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>North Carolina</StateName>
      <StateCode>NC</StateCode>
    </Institution>
  </Award>
</rootTag>
