<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>XPS: FULL: DSD: Asynchronous PDE Algorithms for Turbulent Flows at Exascale</AwardTitle>
    <AwardEffectiveDate>08/15/2014</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2017</AwardExpirationDate>
    <AwardAmount>850000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05010000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Computer &amp; Communication Foundati</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Rudolf Eigenmann</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Future exascale computing systems will be available to study important,&lt;br/&gt;compute-intensive applications such as multi-physics multi-scale natural&lt;br/&gt;phenomena and engineering systems typically modeled accurately by partial&lt;br/&gt;differential equations (PDEs).Â  A prime example is turbulence at high Reynolds&lt;br/&gt;numbers, typically found in natural and engineering systems, which comprise an&lt;br/&gt;extremely wide range of spatial and temporal scales and has thus became a Grand&lt;br/&gt;Challenge in scientific computing.&lt;br/&gt;&lt;br/&gt;Many challenges exists that must be overcome before exascale systems&lt;br/&gt;can be utilized effectively. These include communication between&lt;br/&gt;processing elements as well as global synchronizations both of which will&lt;br/&gt;likely be a main bottleneck when millions of billions of processing elements&lt;br/&gt;are utilized in a simulation.&lt;br/&gt;&lt;br/&gt;In this project, the PIs develop novel exascale numerical schemes for PDEs,&lt;br/&gt;especially those describing turbulent flows, that exploit asynchrony from the mathematical to&lt;br/&gt;the software level. These are based on widely used finite differences, compact differentiation and spectral schemes.&lt;br/&gt;Asynchrony offers better performance but also introduces errors in the solution. The new schemes will&lt;br/&gt;be able to trade-off accuracy and performance in a quantitative and predictable manner.&lt;br/&gt;The approach includes (i) rigorous mathematical studies of stability and&lt;br/&gt;accuracy based on numerical analysis and dynamical systems, which will also&lt;br/&gt;provide a framework for the development of new schemes and quantify its&lt;br/&gt;uncertainty, (ii) development of specific elements in a scalable library for parallel&lt;br/&gt;computing to enable portable implementations on current and future machines,&lt;br/&gt;and (iii) physics based modeling of numerical perturbations in&lt;br/&gt;realistic flows.&lt;br/&gt;&lt;br/&gt;The tools, techniques and simulation data in this project&lt;br/&gt;will be integrated in the PIs' educational efforts through graduate mentoring, undergraduate&lt;br/&gt;research and as material for courses in high-performance computing, fluid dynamics and dynamical systems&lt;br/&gt;taught by the PIs.</AbstractNarration>
    <MinAmdLetterDate>08/12/2014</MinAmdLetterDate>
    <MaxAmdLetterDate>08/12/2014</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1439145</AwardID>
    <Investigator>
      <FirstName>Diego</FirstName>
      <LastName>Donzis</LastName>
      <EmailAddress>donzis@tamu.edu</EmailAddress>
      <StartDate>08/12/2014</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Nancy</FirstName>
      <LastName>Amato</LastName>
      <EmailAddress>amato@tamu.edu</EmailAddress>
      <StartDate>08/12/2014</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Raktim</FirstName>
      <LastName>Bhattacharya</LastName>
      <EmailAddress>raktim@tamu.edu</EmailAddress>
      <StartDate>08/12/2014</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Sharath</FirstName>
      <LastName>Girimaji</LastName>
      <EmailAddress>girimaji@aero.tamu.edu</EmailAddress>
      <StartDate>08/12/2014</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Lawrence</FirstName>
      <LastName>Rauchwerger</LastName>
      <EmailAddress>rwerger@cs.tamu.edu</EmailAddress>
      <StartDate>08/12/2014</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Texas A&amp;M Engineering Experiment Station</Name>
      <CityName>College Station</CityName>
      <ZipCode>778454645</ZipCode>
      <PhoneNumber>9794587617</PhoneNumber>
      <StreetAddress>TEES State Headquarters Bldg.</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Texas</StateName>
      <StateCode>TX</StateCode>
    </Institution>
    <ProgramElement>
      <Code>8283</Code>
      <Text>Exploiting Parallel&amp;Scalabilty</Text>
    </ProgramElement>
  </Award>
</rootTag>
