<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER: Studying Emotional Responses of Children with Autism in Interaction with Facially Expressive Social Robots</AwardTitle>
    <AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2016</AwardExpirationDate>
    <AwardAmount>80000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Directorate for Computer &amp; Information Science &amp; Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Gregory Chirikjian</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Recent research suggests that children with autism exhibit certain positive social behaviors when interacting with robots when compared to their peers that do not interact with robots. These investigations suggest that interaction with robots may be a promising approach for rehabilitation of children with autism. Despite the positive signs and observations reported in the literature, research on using social robots for autism therapy is in its infancy and more fundamental and exploratory studies should be carried out before one can study the effectiveness and clinical impact of robots for autism therapy.&lt;br/&gt;&lt;br/&gt;This project explores several research questions on emotional and behavioral response of children with autism when interacting with a facially expressive robot. Representative questions include: (1) Do children with autism recognize facial expressions shown by an expressive robot similarly to typically developed (TD) children? (2) Should the robot use body gesture and movement in conjunction with facial expression to better convey emotion to children with autism? (3) How do physiological responses of Autistic and TD children vary in interaction with a human versus a robot? To address these questions, the research team plans to recruit a group of children diagnosed with High Functioning Autism and TD children to interact with a facially expressive robot. The sessions are video recorded and analyzed using state-of-the-art automatic computer vision algorithms for facial expression recognition. Children's physiological and emotional responses are also acquired using Electro Dermal Activity (EDA) sensors. The EDA signals are used to create a computational affective model to describe and compare the arousal (excitement) level of the two groups of children in interaction with the robot. Results from this study can be used in designing robot-assisted therapy for human mental and social disabilities such as designing interventions for children suffering from autism, depression, or attention disorder. In addition, the affective model can impact the measurement of emotional conditions in experimental non-interactive protocols. Data generated in this project are a rich source for further analysis by other researchers.</AbstractNarration>
    <MinAmdLetterDate>08/22/2014</MinAmdLetterDate>
    <MaxAmdLetterDate>08/22/2014</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1450933</AwardID>
    <Investigator>
      <FirstName>Mohammad</FirstName>
      <LastName>Mahoor</LastName>
      <EmailAddress>mmahoor@du.edu</EmailAddress>
      <StartDate>08/22/2014</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Denver</Name>
      <CityName>Denver</CityName>
      <ZipCode>802080000</ZipCode>
      <PhoneNumber>3038712000</PhoneNumber>
      <StreetAddress>2199 S. University Blvd.</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Colorado</StateName>
      <StateCode>CO</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7916</Code>
      <Text>EAGER</Text>
    </ProgramReference>
  </Award>
</rootTag>
