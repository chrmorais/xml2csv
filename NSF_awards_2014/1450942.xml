<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER: Collaborative Research: A Computational Model for Evaluating the Quality of Citizen Science Contributions</AwardTitle>
    <AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2015</AwardExpirationDate>
    <AwardAmount>37800</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>William Bainbridge</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Citizen science is a form of research collaboration that involves members of the public in scientific projects, bringing multiple voices and ideas to problem solving and community participation. Citizen science can be powerful because while specific individuals may lack formal expertise and be limited in their ability to contribute high-quality data and new directions, a crowd of individuals may collectively possess the expertise and creativity necessary for identifying and solving difficult problems. However, a major concern for collecting scientific data from the crowd is the varied quality of the contributed data and their relevance to scientific hypotheses. The PIs will explore the potential for deriving metrics from research on computational creativity to automatically assess the quality of citizen science data as a complement to existing research on human assessment of data quality. The project will also explore how the automated assessment of quality can be incorporated into an agent that makes suggestions to individuals in the crowd about the quality of their data, resulting in a prototype for a computational agent that measures the novelty and value of a cizen science contribution. This project will inform future research in computational agents that learn from and contribute to the crowd in order to address challenges associated with the quality of the data and ideas from crowdsourcing in citizen science. &lt;br/&gt;&lt;br/&gt;More specifically, the project includes a) development of a model of citizen-science-data quality based on the notion that good contributions are not just reliable and accurate but also novel and surprising; b) an evaluation of the model against citizen-science data that has been labeled by humans for quality; and c) initial studies of the effect of computational quality feedback on the behavior and perception of members of the crowd. Extending quality assessment to include creativity and being able to make such assessments automatically is potentially tranformative for citizen science projects. The PIs will demonstrate their agent-based model of quality in citizen science projects including their own NatureNet project, which involves crowd participants in data collection in nature preserves and also in the design of scientific challenges and interaction experience that facilitate data collection.</AbstractNarration>
    <MinAmdLetterDate>08/18/2014</MinAmdLetterDate>
    <MaxAmdLetterDate>08/18/2014</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1450942</AwardID>
    <Investigator>
      <FirstName>Jennifer</FirstName>
      <LastName>Preece</LastName>
      <EmailAddress>preece@umd.edu</EmailAddress>
      <StartDate>08/18/2014</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Maryland College Park</Name>
      <CityName>COLLEGE PARK</CityName>
      <ZipCode>207425141</ZipCode>
      <PhoneNumber>3014056269</PhoneNumber>
      <StreetAddress>3112 LEE BLDG</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Maryland</StateName>
      <StateCode>MD</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7367</Code>
      <Text>Cyber-Human Systems (CHS)</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7367</Code>
      <Text>Cyber-Human Systems</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7916</Code>
      <Text>EAGER</Text>
    </ProgramReference>
  </Award>
</rootTag>
