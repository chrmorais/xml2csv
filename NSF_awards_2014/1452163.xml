<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CAREER: Role of geometry in dynamical modeling of human movement: Applications to activity quality assessment across Euclidean, non-Euclidean, and function spaces</AwardTitle>
    <AwardEffectiveDate>06/15/2015</AwardEffectiveDate>
    <AwardExpirationDate>05/31/2020</AwardExpirationDate>
    <AwardAmount>223714</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05010000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Computer &amp; Communication Foundati</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>John Cozzens</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Human movement is a complex multi-dimensional dynamical process arising out of complex non-linear interactions between various muscles and joints as well as interactions with external forces and objects. These physical factors often impose certain analytical constraints on movement data obtained from external sensors, often with associated geometric representations. Examples of such representations abound in the area of human activity analysis, where several contemporary and emerging human shape and movement representations such as silhouettes, stick-figure sequences, orientation signals, and optical- flow have intricate signal spaces, often described in the language of Riemannian geometry. The research thrusts focus on foundational methods for extracting meaningful dynamical attributes that will dovetail into the application thrust. The application centers on computational modeling of qualities of physical activities from low-fidelity sensing infrastructure, which is an important component for technology-mediated physical rehabilitation and preventive interventions.&lt;br/&gt;&lt;br/&gt;Classical vector-valued signal processing and machine learning has had a large impact in the area of understanding and modeling human activities, but their applicability is significantly limited when it comes to signal-spaces with non-Euclidean geometry. This research project aims to advance a new class of robust, non-parametric dynamical modeling approaches, which will extend from classical vector-valued observation spaces, to finite-dimensional Riemannian manifolds, as well as to infinite-dimensional function-spaces. In order to be general enough to account for various geometric spaces as mentioned here, a framework that is free of restrictive assumptions on parametric forms of dynamics is needed. Further, integrating dynamical analysis with Riemannian geometric theory allows the analysis to extend to several feature spaces including depth maps, shape sequences, stick-figures, and orientation data, without re-defining the fundamental models for activity analysis.</AbstractNarration>
    <MinAmdLetterDate>01/28/2015</MinAmdLetterDate>
    <MaxAmdLetterDate>01/28/2015</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1452163</AwardID>
    <Investigator>
      <FirstName>Pavan</FirstName>
      <LastName>Turaga</LastName>
      <EmailAddress>pavan.turaga@asu.edu</EmailAddress>
      <StartDate>01/28/2015</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Arizona State University</Name>
      <CityName>TEMPE</CityName>
      <ZipCode>852816011</ZipCode>
      <PhoneNumber>4809655479</PhoneNumber>
      <StreetAddress>ORSPA</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Arizona</StateName>
      <StateCode>AZ</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7797</Code>
      <Text>COMM &amp; INFORMATION FOUNDATIONS</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>1045</Code>
      <Text>CAREER: FACULTY EARLY CAR DEV</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7936</Code>
      <Text>SIGNAL PROCESSING</Text>
    </ProgramReference>
  </Award>
</rootTag>
